{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dezKQX6aF8vN"
      },
      "outputs": [],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.blank('en')\n",
        "doc = nlp('Dr. Strange loves pav bhaji of mumbai as it costs only 2$ per plate.')\n",
        "for token in doc:\n",
        "  print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7u8rttFIO9j",
        "outputId": "3179781d-29b2-490e-a4b1-b66934097175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dr.\n",
            "Strange\n",
            "loves\n",
            "pav\n",
            "bhaji\n",
            "of\n",
            "mumbai\n",
            "as\n",
            "it\n",
            "costs\n",
            "only\n",
            "2\n",
            "$\n",
            "per\n",
            "plate\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(nlp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "GbByp2H0J4l6",
        "outputId": "087804fa-cfcd-460d-ff82-f750662a3cec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.lang.en.English"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>spacy.lang.en.English</b><br/>def __call__(text: Union[str, Doc], *, disable: Iterable[str]=SimpleFrozenList(), component_cfg: Optional[Dict[str, Dict[str, Any]]]=None) -&gt; Doc</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/spacy/lang/en/__init__.py</a>A text-processing pipeline. Usually you&#x27;ll load this once per process,\n",
              "and pass the instance around your application.\n",
              "\n",
              "Defaults (class): Settings, data and factory methods for creating the `nlp`\n",
              "    object and processing pipeline.\n",
              "lang (str): IETF language code, such as &#x27;en&#x27;.\n",
              "\n",
              "DOCS: https://spacy.io/api/language</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 22);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYouq1yVJ7PZ",
        "outputId": "4cd1ac6d-74b3-45ae-9e0b-ff4b186364f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.doc.Doc"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShXBlef2Id5q",
        "outputId": "8162ce95-94fc-4293-86ba-5e2448b8b819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "spacy.tokens.token.Token"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc[5:9]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AF2JDmMEKCZQ",
        "outputId": "9167ee86-23c1-407c-fac6-987d57afd08b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "of mumbai as it"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Tony gave two $ to Peter.\")"
      ],
      "metadata": {
        "id": "gyp-SE-_KN6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token0=doc[0]\n",
        "token0.is_alpha"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKXHS3kkKOv4",
        "outputId": "cc9b81c1-da5b-4752-a96b-5c66a1d68254"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token2=doc[2]\n",
        "token2.like_url"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwLdIrkTKWKR",
        "outputId": "2ab9ac78-9417-4c4c-cbbc-5fb8bf94bcc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token3=doc[3]\n",
        "token3.is_currency"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNYzaZOpKjvb",
        "outputId": "82a9f556-6499-4421-a501-29d4256e6dd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\")"
      ],
      "metadata": {
        "id": "QvrD0ttfL1_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentense in doc.sents:\n",
        "  print(sentense)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "zy_H8OA6L2rx",
        "outputId": "df562957-323a-46c7-e958-5deec733e57e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "[E030] Sentence boundaries unset. You can add the 'sentencizer' component to the pipeline with: `nlp.add_pipe('sentencizer')`. Alternatively, add the dependency parser or sentence recognizer, or set sentence boundaries by setting `doc[i].is_sent_start`.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-631e39e706cb>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msentense\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentense\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/spacy/tokens/doc.pyx\u001b[0m in \u001b[0;36msents\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: [E030] Sentence boundaries unset. You can add the 'sentencizer' component to the pipeline with: `nlp.add_pipe('sentencizer')`. Alternatively, add the dependency parser or sentence recognizer, or set sentence boundaries by setting `doc[i].is_sent_start`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.pipeline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qs11dQuqMBIh",
        "outputId": "a0d6f25f-c71e-48f1-bd54-170b710e713f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.add_pipe('sentencizer')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDvwxquAMJKZ",
        "outputId": "95b8e1d1-ddda-4dd3-f1f3-c0ccd8dafa63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.pipeline.sentencizer.Sentencizer at 0x7c1276a24680>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.pipeline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbuMue_nMLwz",
        "outputId": "06778342-5eb8-481c-88e8-0a3f0aa07852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('sentencizer', <spacy.pipeline.sentencizer.Sentencizer at 0x7c1276a24680>)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\")"
      ],
      "metadata": {
        "id": "VY81x4Z9MfGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentense in doc.sents:\n",
        "  print(sentense)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Va4yTz2iMOtY",
        "outputId": "363002a6-171d-4afa-adff-5d403bf4608f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dr. Strange loves pav bhaji of mumbai.\n",
            "Hulk loves chat of delhi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text='''\n",
        "Look for data to help you address the question. Governments are good\n",
        "sources because data from public research is often freely available. Good\n",
        "places to start include http://www.data.gov/, and http://www.science.\n",
        "gov/, and in the United Kingdom, http://data.gov.uk/.\n",
        "Two of my favorite data sets are the General Social Survey at http://www3.norc.org/gss+website/,\n",
        "and the European Social Survey at http://www.europeansocialsurvey.org/.\n",
        "'''"
      ],
      "metadata": {
        "id": "keM372p2Ms_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(text)\n",
        "url = []\n",
        "for word in doc:\n",
        "  if word.like_url:\n",
        "    url.append(word)\n",
        "print(url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWSA_zt4MvWZ",
        "outputId": "9d29f355-694d-43f9-e85c-43aee250aa33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[http://www.data.gov/, http://www.science, http://data.gov.uk/., http://www3.norc.org/gss+website/, http://www.europeansocialsurvey.org/.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transactions = \"Tony gave two $ to Peter, Bruce gave 500 € to Steve\"\n",
        "doc1 = nlp(transactions)\n",
        "for word in doc1:\n",
        "  print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvPWlyAoNQKe",
        "outputId": "1e360509-8aeb-493f-e1d0-538bdd7981e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tony\n",
            "gave\n",
            "two\n",
            "$\n",
            "to\n",
            "Peter\n",
            ",\n",
            "Bruce\n",
            "gave\n",
            "500\n",
            "€\n",
            "to\n",
            "Steve\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "curr=[]\n",
        "index=-1\n",
        "for word in doc1:\n",
        "  if word.is_currency:\n",
        "    curr.append(doc1[index:index+2])\n",
        "  index+=1\n",
        "\n",
        "curr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKUeJ2QcOTC-",
        "outputId": "8b81bd3d-1bc8-4e90-b13a-e37afbd2c89e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[two $, 500 €]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spacy Language Processing Pipelines Tutorial"
      ],
      "metadata": {
        "id": "Kaqq6zdcdsie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.blank('en')\n",
        "nlp.pipeline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7D6dcs55dtEs",
        "outputId": "5397f97d-d0a4-49ec-9ac7-cf5e51398070"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Captain america ate 100$ of samosa. Then he said I can do this all day.\")\n",
        "for token in doc:\n",
        "  print(token)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuQCQoTAd4qT",
        "outputId": "d6cd4552-0404-4b23-dd82-319417f93813"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Captain\n",
            "america\n",
            "ate\n",
            "100\n",
            "$\n",
            "of\n",
            "samosa\n",
            ".\n",
            "Then\n",
            "he\n",
            "said\n",
            "I\n",
            "can\n",
            "do\n",
            "this\n",
            "all\n",
            "day\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Now we download trained pipeline\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc = nlp(\"Captain america ate 100$ of samosa. Then he said I can do this all day.\")\n",
        "nlp.pipeline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLGQPi5aeZ__",
        "outputId": "7ab33600-bed4-4716-fef4-f09aae218e46"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x7e2bf31cf4c0>),\n",
              " ('tagger', <spacy.pipeline.tagger.Tagger at 0x7e2bf31ceb60>),\n",
              " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x7e2bf31a1690>),\n",
              " ('attribute_ruler',\n",
              "  <spacy.pipeline.attributeruler.AttributeRuler at 0x7e2bf3f9f200>),\n",
              " ('lemmatizer',\n",
              "  <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x7e2bf33e3c80>),\n",
              " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x7e2bf31a11c0>)]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Part of Speech Tagging\n",
        "for token in doc:\n",
        "  print(token,' | ',token.pos_,' | ',token.lemma_,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDt9rntBeoA8",
        "outputId": "2d66b919-006c-4c99-f92c-afa6ba7ccb21"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Captain  |  PROPN  |  Captain\n",
            "america  |  PROPN  |  america\n",
            "ate  |  VERB  |  eat\n",
            "100  |  NUM  |  100\n",
            "$  |  NUM  |  $\n",
            "of  |  ADP  |  of\n",
            "samosa  |  PROPN  |  samosa\n",
            ".  |  PUNCT  |  .\n",
            "Then  |  ADV  |  then\n",
            "he  |  PRON  |  he\n",
            "said  |  VERB  |  say\n",
            "I  |  PRON  |  I\n",
            "can  |  AUX  |  can\n",
            "do  |  VERB  |  do\n",
            "this  |  PRON  |  this\n",
            "all  |  DET  |  all\n",
            "day  |  NOUN  |  day\n",
            ".  |  PUNCT  |  .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Named Entity recognition\n",
        "doc = nlp(\"Tesla Inc is going to acquire twitter for $45 billion\")\n",
        "\n",
        "for token in doc.ents:\n",
        "  print(token,' | ',token.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeelDzGGfLAl",
        "outputId": "ff8cc906-7b4a-4ed5-de7d-2626597d3774"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla Inc  |  ORG\n",
            "$45 billion  |  MONEY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Adding a component to blank pipeline\n",
        "source_nlp = spacy.load('en_core_web_sm')\n",
        "nlp = spacy.blank('en')\n",
        "\n",
        "nlp.add_pipe('ner',source= source_nlp)\n",
        "nlp.pipeline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vjyCEawfsUe",
        "outputId": "cd4f2bcf-9b13-407e-852c-879d00b7ee96"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ner', <spacy.pipeline.ner.EntityRecognizer at 0x7e2bf06a4200>)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Tesla Inc is going to acquire twitter for $45 billion\")\n",
        "for token in doc.ents:\n",
        "  print(token,' | ',token.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SJFpZrFgLLF",
        "outputId": "bcfc85ba-e5a1-4044-f64b-09c0417a7c6c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla Inc  |  ORG\n",
            "$45 billion  |  MONEY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "  print(token,' | ',token.pos_,' | ',token.lemma_,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_RDL3_QgXMW",
        "outputId": "449e4425-0158-4aff-a1aa-6c740cc2d61a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla  |    |  \n",
            "Inc  |    |  \n",
            "is  |    |  \n",
            "going  |    |  \n",
            "to  |    |  \n",
            "acquire  |    |  \n",
            "twitter  |    |  \n",
            "for  |    |  \n",
            "$  |    |  \n",
            "45  |    |  \n",
            "billion  |    |  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise PoS"
      ],
      "metadata": {
        "id": "B2ftOz9uVHcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''Ravi and Raju are the best friends from school days.They wanted to go for a world tour and\n",
        "visit famous cities like Paris, London, Dubai, Rome etc and also they called their another friend Mohan to take part of this world tour.\n",
        "They started their journey from Hyderabad and spent next 3 months travelling all the wonderful cities in the world and cherish a happy moments!\n",
        "'''\n",
        "\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc = nlp(text)"
      ],
      "metadata": {
        "id": "6gpQf1N6VJyp"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "  if token.pos_ == 'PROPN':\n",
        "    print(token,' | ',token.pos_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6B9ux7qVYTv",
        "outputId": "a49a1e29-b9b8-4048-9755-3a82e5fd8403"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raju  |  PROPN\n",
            "Paris  |  PROPN\n",
            "London  |  PROPN\n",
            "Dubai  |  PROPN\n",
            "Rome  |  PROPN\n",
            "Mohan  |  PROPN\n",
            "Hyderabad  |  PROPN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp('''The Top 5 companies in USA are Tesla, Walmart, Amazon, Microsoft, Google and the top 5 companies in\n",
        "India are Infosys, Reliance, HDFC Bank, Hindustan Unilever and Bharti Airtel''')\n",
        "\n",
        "for token in doc.ents:\n",
        "  if token.label_ == 'ORG':\n",
        "    print(token.ents, ' | ', token.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5glRR7aWV95e",
        "outputId": "1272a5f1-cbcb-43ab-d55d-57e9ecddccde"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Tesla]  |  ORG\n",
            "[Walmart]  |  ORG\n",
            "[Amazon]  |  ORG\n",
            "[Microsoft]  |  ORG\n",
            "[Google]  |  ORG\n",
            "[Infosys]  |  ORG\n",
            "[Reliance]  |  ORG\n",
            "[HDFC Bank]  |  ORG\n",
            "[Hindustan Unilever]  |  ORG\n",
            "[Bharti]  |  ORG\n"
          ]
        }
      ]
    }
  ]
}